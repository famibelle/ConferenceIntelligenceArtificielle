# <div style="display: flex; justify-content: center; align-items: center; height: 100vh; text-align: center; font-size: 10vw; font-weight: bold; width: 100%;">L'Intelligence Artificielle</div>



---

Maitre Corbeau sur un arbre ?

---

Maitre Corbeau sur un arbre perch√©
http://andreetgyps.a.n.pic.centerblog.net/o/6b0e0247.jpg

---
# Tokenisation

Les tokens en traitement du langage naturel (NLP) sont comme les syllabes en po√©sie. Tout comme les syllabes sont les √©l√©ments constitutifs du rythme et de la structure d'un po√®me, les tokens sont les unit√©s fondamentales qui permettent aux mod√®les d'IA de traiter et de comprendre le texte.

## "Maitre Corbeau sur un arbre perch√©" ‚Üí d√©casyllabe
- **Syllabes dans un po√®me :** Maitre Corbeau sur un arbre perch√©.
- **Tokens en NLP :** [Mai ##tre Cor ##beau sur un ar### bre perch√©.].

---

# Token dans les Mod√®les d'IA

La limite de tokens d√©finit le nombre maximum de tokens qu'un mod√®le peut traiter dans une seule entr√©e. Des limites de tokens plus √©lev√©es permettent de g√©rer des contextes plus longs, rendant les mod√®les plus efficaces pour des t√¢ches comme la synth√®se, l'analyse de code et la g√©n√©ration de documents.

| Mod√®le         | Taille Max (tokens) | Pages Livre de Poche Approx. |
|----------------|---------------------|------------------------------|
| GPT-5          | 128 000             | ~512                         |
| Llama 3.1      | 128 000             | ~512                         |
| Mistral Large  | 64 000              | ~256                         |

---

# Embedding

## Transformer les Tokens en Repr√©sentations Num√©riques

<div style="display: flex; align-items: center; gap: 20px;">

    <div style="flex: 1;">

L'embedding transforme les tokens en vecteurs, qui servent de v√©ritables points d'entr√©e pour le LLM.

    </div>

    <div style="flex: 1;">

![Exemple d'Embedding](https://causewriter.ai/wp-content/uploads/2023/08/image-2.png)

    </div>
</div>

---

# Comment la Tokenisation et l'Embedding Fonctionnent Ensemble :
**Tokenisation :**
- Divise le texte en tokens (par exemple, mots, sous-mots ou caract√®res).
- Exemple : "Maitre Corbeau sur un arbre perch√©" ‚Üí [Mai ##tre Cor ##beau sur un ar### bre perch√©.].

**Embedding :**
- Associe chaque token √† un vecteur de haute dimension dans un espace continu.
- Exemple : [Mai ##tre Cor ##beau sur un ar### bre perch√©.]. ‚Üí [[0.12, 0.45, ...], [0.34, 0.67, ...], [0.89, 0.23, ...]].

---

# Pourquoi l'Embedding est Important :
- **Compr√©hension S√©mantique :** Les tokens ayant des significations similaires ont des embeddings plus proches dans l'espace vectoriel.


```mermaid
graph LR
  A["Input Phrase: 'Maitre Corbeau sur un arbre perch√©'"] --> B["Tokenization: [Mai ##tre Cor ##beau sur un ar### bre perch√©.]"]
  B --> C["Embedding: Dense Numerical Vectors"]

  C["Tokenization Output"]
  C --> D["Token: 'Mai'"]
  D --> D1["Vector: [0.12, 0.45, 0.78, ...]"]
  C --> E["Token: '##tre'"]
  E --> E1["Vector: [0.34, 0.67, 0.89, ...]"]
  C --> F["Token: 'Cor'"]
  F --> F1["Vector: [0.56, 0.23, 0.91, ...]"]
  C --> G["Token: '##beau'"]
  G --> G1["Vector: [0.78, 0.12, 0.34, ...]"]
  C --> H["Token: 'sur'"]
  H --> H1["Vector: [0.45, 0.89, 0.67, ...]"]
  ```

---



## ü§î Qu‚Äôest-ce que l‚ÄôIA ?
- Intelligence artificielle = capacit√© d‚Äôun programme √† **simuler l‚Äôintelligence humaine**
- Exemple : reconna√Ætre des images, jouer √† des jeux, comprendre le langage

---

## üåü Pourquoi l‚ÄôIA est importante aujourd‚Äôhui
- Smartphones, assistants vocaux, recommandations
- IA pour la sant√©, l‚Äôindustrie, l‚Äôart et la science

---

## 1950 ‚Äì Alan Turing
- Publie "Computing Machinery and Intelligence"
- Propose le **Test de Turing**
- Question : une machine peut-elle penser ?

---

## 1956 ‚Äì Naissance officielle de l‚ÄôIA
- Conf√©rence de **Dartmouth**
- Objectif : cr√©er des machines capables de penser
- D√©but de l‚ÄôIA symbolique

---

## 1960 ‚Äì Perceptrons
- **Frank Rosenblatt** invente le perceptron
- Neurone artificiel = base des r√©seaux de neurones
- Limit√© : ne r√©sout pas les probl√®mes non lin√©aires

---

## 1980 ‚Äì Perceptrons multicouches
- Introduction des **couches multiples**
- Permet de r√©soudre des probl√®mes plus complexes
- Base des IA modernes

---

## 1980s ‚Äì Geoffrey Hinton
- Travaux sur **l‚Äôapprentissage profond**
- Red√©couvre et perfectionne les r√©seaux multicouches
- Pr√©curseur du deep learning moderne

---

## 1980s ‚Äì Yann LeCun
- Travaux sur les **CNN (Convolutional Neural Networks)**
- Applications : reconnaissance de chiffres manuscrits
- D√©but du succ√®s du deep learning

---

## 1990s ‚Äì Yoshua Bengio
- Travaux sur **les repr√©sentations distribu√©es**
- R√©seaux neuronaux plus profonds
- Pr√©curseur des r√©seaux tr√®s larges et profonds actuels

---

## 1997 ‚Äì Deep Blue
- IA d‚ÄôIBM bat Garry Kasparov aux √©checs
- Exemple d‚ÄôIA sp√©cialis√©e
- D√©monstration de puissance de calcul + strat√©gie

---

## 2006 ‚Äì Renaissance du Deep Learning
- Hinton et Bengio relancent le deep learning
- Techniques modernes : **r√©seaux profonds et GPU**
- Pr√©paration pour r√©volution visuelle et textuelle

---

## 2012 ‚Äì AlexNet
- R√©seau de neurones convolutif profond
- Gagne le concours **ImageNet**
- R√©volutionne la vision par ordinateur

---

## üîç Impact d‚ÄôAlexNet
- Montre que le deep learning fonctionne √† grande √©chelle
- GPU rend l‚Äôentra√Ænement possible
- D√©but de la domination du deep learning dans l‚Äôindustrie

---

## üéÆ IA et Jeux vid√©o
- IA apprend en jouant
- Exemple : OpenAI Five, AlphaGo
- Strat√©gie, anticipation, coordination

---

## 2016 ‚Äì AlphaGo
- D√©velopp√© par **Demis Hassabis, DeepMind**
- Bat le champion de Go
- Apprentissage par renforcement + r√©seaux profonds

---

## üåå SETI @ Home
- Projet pour d√©tecter vie extraterrestre
- Utilise la puissance de calcul **des ordinateurs des b√©n√©voles**
- Exemple de **distributed computing** et science collaborative

---

## üß† Le cerveau humain
- Taille moyenne : 1600 cm¬≥
- N√©andertal : 1300 cm¬≥
- Limit√© pour nouveaux neurones
- Synapses : pratiquement illimit√©es

https://image1.slideserve.com/2915781/brain-size-in-mammals-l.jpg
---

## ‚ö° √ânergie : cerveau vs IA
| Syst√®me | Consommation |
|---------|--------------|
| Cerveau humain | ~20 W |
| GPU IA | ~250‚Äì400 W par unit√© |

---

## üß† Comparatif cerveau vs IA
- Cerveau : flexible, √©conome en √©nergie, g√©n√©raliste
- IA : rapide, sp√©cialis√©e, √©nergivore

---

## ‚è≥ Singularit√© technologique
- Moment hypoth√©tique o√π IA surpassera l‚Äôintelligence humaine
- D√©bat : emploi, √©thique, contr√¥le
- Sujet fascinant et controvers√©

---

## ü§ñ L‚ÄôAGI : qu‚Äôest-ce que c‚Äôest ?
- AGI = **Artificial General Intelligence**
- IA capable de comprendre, apprendre et agir **comme un humain**
- Contrairement √† l‚ÄôIA actuelle, qui est sp√©cialis√©e

---

## üß† Diff√©rence IA sp√©cialis√©e vs AGI
| IA sp√©cialis√©e | AGI |
|----------------|-----|
| Fait une seule t√¢che | Peut apprendre toutes les t√¢ches |
| Exemple : AlphaGo | Exemple : r√©soudre un probl√®me, cr√©er, planifier |
| Limit√© √† un domaine | Flexible et g√©n√©raliste |

---

## üåå Pourquoi l‚ÄôAGI est fascinante
- Potentiel √©norme : science, m√©decine, exploration spatiale
- Risques : contr√¥le, √©thique, emploi
- Question cl√© : que se passe-t-il si elle devient **plus intelligente que nous** ?

---

## üîÆ Vers l‚ÄôAGI
- Combinaison :
  - R√©seaux profonds
  - M√©moire et planification
  - Compr√©hension du langage et raisonnement
- Objectif : IA **polyvalente et autonome**

---

## ‚öñÔ∏è √âthique et AGI
- S√©curit√© : √©viter comportements impr√©visibles
- Transparence : comment prend-elle ses d√©cisions ?
- Responsabilit√© : qui contr√¥le l‚ÄôAGI ?

---

## üñ•Ô∏è D√©monstration : Moshi de Kuytai
- G√©n√©ration de texte et images
- Interaction avec le public
- Illustrer puissance et limites de l‚ÄôIA

---

## üßÆ Types d‚Äôapprentissage
- Supervis√© : donn√©es √©tiquet√©es
- Non supervis√© : motifs d√©tect√©s automatiquement
- Par renforcement : essais et erreurs + r√©compenses

---

## üîç Apprentissage supervis√©
- Exemple : reconnaissance d‚Äôimages (chat vs chien)
- IA apprend √† partir d‚Äôexemples connus

---

## üîç Apprentissage non supervis√©
- IA d√©couvre des motifs sans √©tiquettes
- Exemple : clustering, segmentation

---

## üîÑ Apprentissage par renforcement
- IA agit dans un environnement, re√ßoit feedback
- Exemple : AlphaGo, OpenAI Five

---

## ‚öôÔ∏è GPU et Deep Learning
- Calcul parall√®le massif
- Permet l‚Äôentra√Ænement rapide de r√©seaux profonds
- Diff√©rence cl√© avec CPU : vitesse et √©chelle

---

## üåê IA et vie quotidienne
- Smartphones, assistants vocaux
- Recommandations : Netflix, YouTube, Spotify
- Voitures autonomes

---

## üè• IA et sant√©
- D√©tection pr√©coce de maladies
- Analyse d‚Äôimages m√©dicales
- Personnalisation des traitements

---

## üé® IA et cr√©ativit√©
- G√©n√©ration d‚Äôimages, textes, musique
- Limites : cr√©ativit√© encadr√©e, pas d‚Äôintuition


---

# Neurones Artificiels  
<div style="display: flex; align-items: center; gap: 20px;">
    <div style="flex: 1;">

Mod√®le math√©matique du neurone artificiel  

Fonctions d'activation : ReLU, Sigmoid, Tanh  

Similarit√©s et diff√©rences avec les neurones biologiques ?  

</div>

<div style="display: flex; align-items: center; gap: 20px;">
    <div style="flex: 1;">

    ![Structure du Neurone Artificiel](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Artificial_neuron_structure.svg/1024px-Artificial_neuron_structure.svg.png)  
    *Illustration d'un neurone artificiel*
    </div>
</div>


---

# R√©seaux de Neurones Artificiels

Les r√©seaux de neurones artificiels (RNA) sont des mod√®les computationnels inspir√©s de la structure et du fonctionnement des r√©seaux neuronaux biologiques. 

Ils sont compos√©s de couches interconnect√©es de neurones artificiels, o√π chaque neurone traite les entr√©es, applique une fonction d'activation et transmet la sortie √† la couche suivante. 

**Les RNA** sont largement utilis√©s pour des t√¢ches telles que la reconnaissance de motifs, la classification et la r√©gression dans divers domaines.

---

# Param√®tres et Poids dans les R√©seaux de Neurones

Dans les r√©seaux de neurones, les **param√®tres** font r√©f√©rence aux valeurs ajustables que le mod√®le apprend pendant l'entra√Ænement. Ceux-ci incluent :

**Poids :**

- Repr√©sentent la force de la connexion entre les neurones.
- Ajust√©s pendant l'entra√Ænement pour minimiser l'erreur entre les sorties pr√©dites et r√©elles.

**Biais :**
- Ajout√©s √† la somme pond√©r√©e des entr√©es pour d√©caler la fonction d'activation.
- Aident le mod√®le √† mieux s'adapter aux donn√©es en permettant une flexibilit√© dans les fronti√®res de d√©cision.

---

# Param√®tres et Poids dans les R√©seaux de Neurones

<div style="display: flex; align-items: center; gap: 20px;">
    <div style="flex: 1;">

**Pourquoi Ils Sont Importants :**

- **Les poids et les biais** sont les composants essentiels qui permettent aux r√©seaux de neurones d'apprendre des motifs et de faire des pr√©dictions. En mettant √† jour de mani√®re it√©rative ces valeurs √† l'aide d'algorithmes d'optimisation comme la descente de gradient, le r√©seau am√©liore ses performances sur la t√¢che donn√©e.
    </div>

    <div style="flex: 1;">
**Exemple :**

- Dans un r√©seau de neurones simple, si l'entr√©e est `X`, le poids est `W` et le biais est `B`, la sortie d'un neurone est calcul√©e comme :
$$\text{sortie} = \text{fonction\_activation}(W \cdot X + B)$$

    </div>
</div>
---

# Mistral 7B : Nombre de Param√®tres

<div style="display: flex; align-items: center; gap: 20px;">

    <div style="flex: 1;">

Le mod√®le Mistral 7B est un mod√®le de fondation de pointe avec **7 milliards de param√®tres**.


**Comparaison :**
- **GPT-4 :** Environ 175 milliards de param√®tres estim√©s.
- **LLaMA 2 (13B) :** 13 milliards de param√®tres.

    </div>

    <div style="flex: 1;">

![Comparaison des Param√®tres de Mod√®les](https://www.geeky-gadgets.com/wp-content/uploads/2023/09/New-Mistral-7B-instruct-model-from-Mistral-AI.webp)

    </div>
</div>
---

# Perceptron Multicouche (PMC)
<div style="display: flex; align-items: center; gap: 20px;">

    <div style="flex: 1;">

Un Perceptron Multicouche (PMC) est un type de r√©seau de neurones artificiels compos√© d'une couche d'entr√©e, d'une ou plusieurs couches cach√©es et d'une couche de sortie. Chaque couche consiste en des n≈ìuds (neurones) interconnect√©s o√π les entr√©es sont trait√©es √† travers des connexions pond√©r√©es, des fonctions d'activation et des biais. 

Les PMC sont largement utilis√©s pour des t√¢ches d'apprentissage supervis√© telles que la classification et la r√©gression, tirant parti de leur capacit√© √† mod√©liser des relations complexes et non lin√©aires dans les donn√©es.

Le concept du PMC a √©t√© introduit pour la premi√®re fois en 1969 par Marvin Minsky et Seymour Papert dans leur livre *Perceptrons*, qui a pos√© les bases de la recherche sur les r√©seaux de neurones.

    </div>

    <div style="flex: 1;">

![PMC](https://media.licdn.com/dms/image/D5612AQG2n-h9rBE2NA/article-cover_image-shrink_600_2000/0/1701597139460?e=2147483647&v=beta&t=kTHU5V1z66QpFeikBYqQ4Gwgu-o3V8DlwKWOub6Rr2M)

    </div>

</div>
---



---
# ML : Apprentissage par Renforcement‚Äã

<div style="display: flex; align-items: center; gap: 20px;">
    <div style="flex: 1;">
Agents apprenant par essais et erreurs‚Äã

Syst√®mes de r√©compense‚Äã
    </div>

    <div style="flex: 1;">

<iframe width="560" height="315" src="https://www.youtube.com/embed/spfpBrBjntg?si=68Z-oEMzvfxk8p6x&autoplay=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

    </div>

</div>
---

# ML : Apprentissage par Renforcement‚Äã
<div style="display: flex; align-items: center; gap: 20px;">
    <div style="flex: 1;">

- Syst√®mes de conduite autonome apprenant des strat√©gies de conduite optimales par simulation.
- Syst√®mes de r√©gulateur de vitesse adaptatif optimisant l'efficacit√© √©nerg√©tique et la s√©curit√©.
- Syst√®mes d'assistance au stationnement apprenant √† naviguer dans des sc√©narios de stationnement complexes.

    </div>
    <div style="flex: 1;">  

<iframe width="560" height="315" src="https://www.youtube.com/embed/KPLYhRBCcvk?autoplay=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

**Source :** [AlphaStar : Niveau grand ma√Ætre dans StarCraft II utilisant l'apprentissage par renforcement multi-agents](https://deepmind.google/discover/blog/alphastar-grandmaster-level-in-starcraft-ii-using-multi-agent-reinforcement-learning/)

    </div>
</div>
---


## R√©seau de Neurones en Action

<div style="display: flex; align-items: center; gap: 20px;">

    <div style="flex: 1;">

L'animation montre le processus de reconnaissance de chiffres manuscrits √† l'aide d'un r√©seau de neurones. 

Elle visualise comment le mod√®le traite les images d'entr√©e, extrait les caract√©ristiques et pr√©dit le chiffre correspondant.

    </div>

    <div style="flex: 1;">

![R√©seau de Neurones en Action](https://i.makeagif.com/media/3-22-2022/boUeR6.gif)

    </div>
</div>

---

# Base de Donn√©es MNIST : Reconnaissance de Chiffres Manuscrits

<div style="display: flex; align-items: center; gap: 20px;">

    <div style="flex: 1;">

La base de donn√©es MNIST (Modified National Institute of Standards and Technology) est un benchmark largement utilis√© en apprentissage automatique et en vision par ordinateur. Elle se compose de 70 000 images en niveaux de gris de chiffres manuscrits (0 √† 9), chacune de taille 28x28 pixels. La base de donn√©es est utilis√©e pour entra√Æner et √©valuer des mod√®les pour des t√¢ches de reconnaissance de chiffres.

**Importance :**
- MNIST sert de point de d√©part pour tester et comparer les algorithmes d'apprentissage automatique.
- Elle aide √† comprendre comment les r√©seaux de neurones peuvent classifier des nombres bas√©s sur des motifs de pixels.

**Historique :**
- MNIST a √©t√© introduite en 1998 par **Yann LeCun, Corinna Cortes et Christopher J.C. Burges** dans le cadre de leurs recherches sur les r√©seaux de neurones et l'apprentissage automatique.

**Applications :**
- Reconnaissance de chiffres dans les syst√®mes postaux.
- Exp√©riences fondamentales en apprentissage profond.

    </div>
    <div style="flex: 1;">


![Exemple de la Base MNIST](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)

Exemple de reconnaissance de chiffres manuscrits de la base de donn√©es MNIST

    </div>
</div>



---

## **2. Les Bases de l'IA (20 min)**
**Objectif** : Rendre compr√©hensible le fonctionnement de l'IA
- **2.1** Comparaison neurone biologique/neurone artificiel (5 min)
  - Sch√©ma simple : Corps cellulaire/dendrites vs entr√©es/poids
  - Analogie : "Comme une recette de cuisine tr√®s pr√©cise"
- **2.2** Historique accessible (5 min)
  - Alan Turing, Yann Le Cun, SETI@Home
  - Les jeux vid√©o et l'IA (Black & White, Theme Park)
- **2.3** Limites et r√©alit√©s (10 min)
  - Cerveau humain (1600 cm¬≥) vs GPU (consommation √©nerg√©tique)
## üß™ Le Test de Turing : Peut-on Tromper un Humain ?

---
## Le test de Turing
**Principe :**
- Test propos√© par Alan Turing en 1950
- Une machine peut-elle convaincre un humain qu'elle est elle-m√™me humaine lors d'une conversation ?

**Comment √ßa marche :**
1. Un humain dialogue avec deux interlocuteurs cach√©s
2. L'un est une machine, l'autre un humain
3. Si l'humain ne peut pas distinguer qui est qui, la machine "r√©ussit" le test

**Exemple concret :**
- Vous discutez par √©crit avec deux personnes
- L'une parle de ses vacances, l'autre aussi
- Laquelle est l'IA ? Si vous ne pouvez pas le dire, l'IA a r√©ussi !

**Limites du test :**
- R√©ussir ne signifie pas "penser" vraiment
- Une IA peut imiter sans comprendre
- D√©bat : intelligence simul√©e vs intelligence r√©elle

**Aujourd'hui :**
- En 2027 on ne pourra pas faire la disctinction entre un humain et une IA


---

## Applications Concr√®tes (25 min)**
  - G√©n√©ration d'une image simple ("un chat dans un jardin")
  - G√©n√©ration d'un po√®me avec le public
-  Exemples du quotidien (10 min)
  - Reconnaissance vocale, recommandations, traduction automatique
-  D√©tecter l'IA (5 min)
  - "Cette image a-t-elle √©t√© g√©n√©r√©e par une IA ?" (quiz visuel)

---

## **4. Questions Cl√©s (20 min)**
**Objectif** : R√©pondre aux interrogations courantes
- **4.1** "L'IA est-elle plus intelligente que nous ?" (5 min)
  - Non, elle est sp√©cialis√©e (exemple AlphaGo)
- **4.2** "Peut-on lui faire confiance ?" (5 min)
  - Les biais et erreurs de l'IA (exemple de traduction amusante)
- **4.3** "Va-t-elle nous remplacer ?" (5 min)
  - M√©tiers qui √©voluent vs nouveaux m√©tiers
- **4.4** Cr√©ativit√© et IA (5 min)
  - D√©monstration de g√©n√©ration cr√©ative

---

## **5. Enjeux et D√©fis (15 min)**
**Objectif** : Pr√©senter les d√©fis de mani√®re concr√®te
- **5.1** Les biais algorithmiques (5 min)
  - Exemple : Refus de pr√™t √† cause d'une adresse
- **5.2** Impact environnemental (5 min)
  - Comparaison : cerveau (20W) vs IA (centrale √©lectrique)
- **5.3** R√©gulation (5 min)
  - RGPD et IA Act : des r√®gles pour prot√©ger nos donn√©es

---

## **6. Atelier Pratique (10 min)**
**Objectif** : Impliquer le public
- **6.1** Jeu : "Imaginez une application utile de l'IA" (5 min)
  - Exemples : rappel m√©dicaments, tri de photos
- **6.2** Quiz interactif (5 min)
  - "Quelle image a √©t√© g√©n√©r√©e par une IA ?"

---

## **7. Conclusion (15 min)**
**Objectif** : Synth√®se et ouverture
- **7.1** 3 messages cl√©s (5 min)
  - L'IA est un outil puissant mais pas magique
  - Elle peut nous aider mais il faut rester critique
  - Les m√©tiers ne dispara√Ætront pas, ils √©volueront
- **7.2** Ressources accessibles (5 min)
  - Livre : "L'IA pour les Nuls" (Luc Julia)
  - Site : Class'Code (MOOC gratuit)
- **7.3** D√©bat ouvert (5 min)
  - "Quelle question vous intrigue encore sur l'IA ?"

---

## **Support Visuel Recommand√©**
- **Format** : Slides √©pur√©s avec peu de texte
- **Contenu** :
  - Sch√©mas simples (neurone biologique vs artificiel)
  - Images concr√®tes (exemples d'applications)
  - Pas d'animations (comme demand√©)

## **Mat√©riel N√©cessaire**
- Projecteur pour les d√©monstrations
- Acc√®s internet pour les outils interactifs
- Tableau/paperboard pour les sch√©mas

## **Pr√©paration Conseill√©e**
- Pr√©parer 3-4 d√©monstrations interactives
- Imprimer des exemples visuels pour le quiz
- Pr√©voir des pauses pour les questions

---

Ce syllabus respecte vos pr√©f√©rences :
- Pas d'animations
- Adapt√© aux n√©ophytes
- Approche pragmatique avec d√©monstrations
- Sans r√©f√©rence technique complexe
- Avec des pauses pour interaction

Souhaitez-vous que j'ajoute ou modifie des √©l√©ments sp√©cifiques ?
